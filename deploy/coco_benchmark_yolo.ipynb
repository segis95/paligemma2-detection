{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4216bfaa-0c64-4b50-89a8-213c54942ef8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 640x640 (no detections), 23.9ms\n",
      "Speed: 9.3ms preprocess, 23.9ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n"
     ]
    }
   ],
   "source": [
    "from ultralytics import YOLO\n",
    "from pycocotools.coco import COCO\n",
    "from pycocotools.cocoeval import COCOeval\n",
    "from ultralytics.data.converter import coco80_to_coco91_class\n",
    "from ultralytics.utils.ops import xyxy2ltwh\n",
    "from tqdm import tqdm\n",
    "from ultralytics import YOLO\n",
    "import json\n",
    "from yolo_triton_client import TritonYOLOInference\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "\n",
    "model = YOLO(\"yolo11x.pt\")\n",
    "_ = model.predict(Image.fromarray(np.zeros((224,224))))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "146a1161-669d-4fb4-8d1a-d42e53150c42",
   "metadata": {},
   "source": [
    "# 1. Evaluating with ultralytics torch YOLOv11x model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b4d62afb-5689-4474-8662-acbe75392144",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ultralytics 8.3.228 üöÄ Python-3.12.3 torch-2.9.1+cu128 CUDA:0 (NVIDIA GeForce RTX 3090, 24576MiB)\n",
      "\n",
      "WARNING ‚ö†Ô∏è Dataset 'coco.yaml' images not found, missing path '/mnt/d/Sergey/ML/datasets/coco/val2017.txt'\n",
      "\u001b[KDownloading https://ultralytics.com/assets/coco2017labels-segments.zip to '/mnt/d/Sergey/ML/datasets/coco2017labels-segments.zip': 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 168.5MB 16.7MB/s 10.1s10.0s<0.1s\n",
      "\u001b[KUnzipping /mnt/d/Sergey/ML/datasets/coco2017labels-segments.zip to /mnt/d/Sergey/ML/datasets/coco...: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 122232/122232 173.7files/s 11:44<0.0s\n",
      "Downloading 3 file(s) with 3 threads to /mnt/d/Sergey/ML/datasets/coco/images...\n",
      "\u001b[KDownloading http://images.cocodataset.org/zips/val2017.zip to '/mnt/d/Sergey/ML/datasets/coco/images/val2017.zip': 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 777.8MB 11.7MB/s 1:06s 1:06<0.0s353:02\n",
      "\u001b[KUnzipping /mnt/d/Sergey/ML/datasets/coco/images/val2017.zip to /mnt/d/Sergey/ML/datasets/coco/images/val2017...: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 5001/5001 127.3files/s 39.3s0.1s:605\n",
      "\u001b[KDownloading http://images.cocodataset.org/zips/test2017.zip to '/mnt/d/Sergey/ML/datasets/coco/images/test2017.zip': 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 6.2GB 15.7MB/s 6:446:44<0.0s164\n",
      "\u001b[KUnzipping /mnt/d/Sergey/ML/datasets/coco/images/test2017.zip to /mnt/d/Sergey/ML/datasets/coco/images/test2017...: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 40671/40671 109.3files/s 6:12<0.0s5\n",
      "\u001b[KDownloading http://images.cocodataset.org/zips/train2017.zip to '/mnt/d/Sergey/ML/datasets/coco/images/train2017.zip': 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 18.0GB 16.0MB/s 19:1219:12<0.0s\n",
      "\u001b[KUnzipping /mnt/d/Sergey/ML/datasets/coco/images/train2017.zip to /mnt/d/Sergey/ML/datasets/coco/images/train2017...: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 118288/118288 136.1files/s 14:29<0.1s\n",
      "Dataset download success ‚úÖ (2738.5s), saved to \u001b[1m/mnt/d/Sergey/ML/datasets\u001b[0m\n",
      "\n",
      "\u001b[34m\u001b[1mval: \u001b[0mFast image access ‚úÖ (ping: 4.6¬±1.9 ms, read: 19.4¬±11.2 MB/s, size: 198.3 KB)\n",
      "\u001b[K\u001b[34m\u001b[1mval: \u001b[0mScanning /mnt/d/Sergey/ML/datasets/coco/labels/val2017... 4952 images, 48 backgrounds, 0 corrupt: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 5000/5000 365.0it/s 13.7s<0.0s\n",
      "\u001b[34m\u001b[1mval: \u001b[0mNew cache created: /mnt/d/Sergey/ML/datasets/coco/labels/val2017.cache\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 313/313 3.8it/s 1:22<0.2ss\n",
      "                   all       5000      36335      0.737      0.659      0.713      0.549\n",
      "                person       2693      10777      0.835      0.775      0.859      0.657\n",
      "               bicycle        149        314      0.732      0.627      0.684       0.45\n",
      "                   car        535       1918      0.772      0.703      0.772      0.555\n",
      "            motorcycle        159        367      0.797       0.77      0.822      0.589\n",
      "              airplane         97        143      0.865      0.902      0.934      0.808\n",
      "                   bus        189        283      0.859      0.841      0.906      0.802\n",
      "                 train        157        190      0.929      0.892      0.957      0.783\n",
      "                 truck        250        414       0.67      0.558      0.646      0.491\n",
      "                  boat        121        424      0.746      0.574      0.634       0.38\n",
      "         traffic light        191        634      0.748      0.495      0.605      0.347\n",
      "          fire hydrant         86        101      0.935      0.871       0.93      0.801\n",
      "             stop sign         69         75      0.823      0.733      0.803      0.734\n",
      "         parking meter         37         60      0.807      0.683      0.726      0.564\n",
      "                 bench        235        411      0.644      0.445      0.508      0.373\n",
      "                  bird        125        427      0.781       0.51      0.635      0.448\n",
      "                   cat        184        202      0.922      0.916      0.949      0.822\n",
      "                   dog        177        218      0.793      0.862      0.882      0.778\n",
      "                 horse        128        272      0.862      0.875      0.923      0.725\n",
      "                 sheep         65        354      0.771      0.788      0.845       0.65\n",
      "                   cow         87        372      0.834      0.796      0.873      0.704\n",
      "              elephant         89        252       0.83      0.913      0.906      0.771\n",
      "                  bear         49         71      0.922      0.972       0.98      0.837\n",
      "                 zebra         85        266      0.878      0.895       0.95      0.793\n",
      "               giraffe        101        232      0.933       0.94      0.956      0.816\n",
      "              backpack        228        371      0.567      0.367      0.421       0.24\n",
      "              umbrella        174        407      0.686      0.693       0.75      0.561\n",
      "               handbag        292        540       0.57      0.406      0.436      0.269\n",
      "                   tie        145        252      0.768      0.591      0.682      0.495\n",
      "              suitcase        105        299      0.698      0.659      0.739      0.543\n",
      "               frisbee         84        115      0.928      0.903      0.931      0.775\n",
      "                  skis        120        241       0.72      0.527      0.621      0.394\n",
      "             snowboard         49         69      0.744      0.565      0.646      0.487\n",
      "           sports ball        169        260      0.829      0.654      0.715      0.537\n",
      "                  kite         91        327      0.706      0.645      0.712      0.524\n",
      "          baseball bat         97        145      0.749      0.745      0.784       0.55\n",
      "        baseball glove        100        148      0.822      0.689      0.747      0.475\n",
      "            skateboard        127        179      0.847      0.838      0.853      0.684\n",
      "             surfboard        149        267       0.83      0.693      0.778      0.558\n",
      "         tennis racket        167        225      0.898      0.884      0.923      0.706\n",
      "                bottle        379       1013      0.704      0.583      0.673      0.495\n",
      "            wine glass        110        341      0.789      0.636      0.705      0.499\n",
      "                   cup        390        895      0.703      0.624      0.705      0.557\n",
      "                  fork        155        215       0.68      0.682      0.749       0.58\n",
      "                 knife        181        325      0.667      0.456      0.537      0.358\n",
      "                 spoon        153        253      0.542      0.453      0.473       0.35\n",
      "                  bowl        314        623       0.69      0.621      0.669      0.533\n",
      "                banana        103        370      0.562      0.376       0.47      0.313\n",
      "                 apple         76        236      0.495      0.352       0.35       0.25\n",
      "              sandwich         98        177      0.667      0.588      0.633      0.506\n",
      "                orange         85        285      0.553      0.439      0.477      0.385\n",
      "              broccoli         71        312      0.555      0.413      0.476      0.297\n",
      "                carrot         81        365      0.572      0.381       0.44      0.289\n",
      "               hot dog         51        125      0.725      0.552      0.636      0.509\n",
      "                 pizza        153        284      0.752      0.757      0.808      0.639\n",
      "                 donut         62        328      0.747      0.649      0.722      0.588\n",
      "                  cake        124        310      0.696      0.661      0.706      0.503\n",
      "                 chair        580       1771      0.705       0.56      0.642      0.452\n",
      "                 couch        195        261      0.668      0.639      0.705      0.584\n",
      "          potted plant        172        342      0.625      0.544      0.568      0.369\n",
      "                   bed        149        163      0.718      0.693      0.768      0.602\n",
      "          dining table        501        695      0.577      0.537      0.534      0.385\n",
      "                toilet        149        179      0.818      0.849      0.882      0.741\n",
      "                    tv        207        288      0.821      0.799      0.854      0.684\n",
      "                laptop        183        231      0.844      0.795      0.862      0.759\n",
      "                 mouse         88        106      0.857       0.84       0.86      0.691\n",
      "                remote        145        283      0.715      0.615       0.69      0.483\n",
      "              keyboard        106        153      0.717      0.695      0.764      0.611\n",
      "            cell phone        214        262      0.718      0.618      0.673      0.498\n",
      "             microwave         54         55      0.741      0.818      0.845      0.697\n",
      "                  oven        115        143      0.631      0.594      0.634      0.465\n",
      "               toaster          8          9      0.531      0.667      0.641      0.503\n",
      "                  sink        187        225      0.679      0.657      0.684      0.478\n",
      "          refrigerator        101        126      0.771      0.786       0.84      0.738\n",
      "                  book        230       1129      0.589      0.222      0.342      0.211\n",
      "                 clock        204        267      0.806       0.73      0.777      0.581\n",
      "                  vase        137        274      0.651      0.584      0.629       0.46\n",
      "              scissors         28         36      0.569      0.441      0.509      0.438\n",
      "            teddy bear         94        190      0.745      0.695       0.76       0.62\n",
      "            hair drier          9         11      0.637      0.364      0.397      0.246\n",
      "            toothbrush         34         57      0.665      0.544      0.566      0.462\n",
      "Speed: 0.5ms preprocess, 9.7ms inference, 0.0ms loss, 1.0ms postprocess per image\n",
      "Saving /mnt/d/Sergey/ML/paligemma2-detection/deploy/runs/detect/val4/predictions.json...\n",
      "\n",
      "Evaluating faster-coco-eval mAP using /mnt/d/Sergey/ML/paligemma2-detection/deploy/runs/detect/val4/predictions.json and /mnt/d/Sergey/ML/datasets/coco/annotations/instances_val2017.json...\n",
      "Evaluate annotation type *bbox*\n",
      "COCOeval_opt.evaluate() finished...\n",
      "DONE (t=4.35s).\n",
      "Accumulating evaluation results...\n",
      "COCOeval_opt.accumulate() finished...\n",
      "DONE (t=0.00s).\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.546\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.716\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.595\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.377\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.597\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.702\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.400\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.666\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.714\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.558\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.766\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.854\n",
      " Average Recall     (AR) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.902\n",
      " Average Recall     (AR) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.777\n",
      "Results saved to \u001b[1m/mnt/d/Sergey/ML/paligemma2-detection/deploy/runs/detect/val4\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "_ = model.val(data=\"coco.yaml\", augment=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc4bd294-34d8-4606-b819-9289fc141a86",
   "metadata": {},
   "source": [
    "# 2. Evaluating with triton endpoint at localhost:8000/yolo"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b48ace1c-8278-4419-a64a-85138c025a62",
   "metadata": {},
   "source": [
    "## Collecting images with annotations (48 out of 5000 images in val2017 are not annotated)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "33abee77-747b-4e33-9a48-05a9f216aa20",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('../../datasets/coco/annotations/instances_val2017.json', 'r') as f:\n",
    "    data = json.load(f)\n",
    "\n",
    "i2gt = {}\n",
    "for item in data['annotations']:\n",
    "    if item['image_id'] not in i2gt:\n",
    "        i2gt[item['image_id']] = []\n",
    "    item = {x: item[x] for x in {'image_id', 'bbox', 'category_id'}}\n",
    "    i2gt[item['image_id']].append(item)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba024d9d-c640-4eec-93a5-41169a8f95c4",
   "metadata": {},
   "source": [
    "## Running evaluation with triton"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7776af3e-bb81-49dd-807e-1ee47d9c8b5b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 4952/4952 [04:15<00:00, 19.38it/s]\n"
     ]
    }
   ],
   "source": [
    "with TritonYOLOInference(\n",
    "        url=\"localhost:8000\",\n",
    "        model_name=\"yolo\",\n",
    "        preprocess_fn=model.predictor.preprocess,\n",
    "        conf_threshold=0.001,\n",
    "        iou_threshold=0.7,\n",
    "        max_det=300\n",
    ") as inference_client:\n",
    "\n",
    "    my_predictions = []\n",
    "\n",
    "    for image_id in tqdm(i2gt):\n",
    "        # Inference from image path\n",
    "        predictions = inference_client.predict(\n",
    "            f'../../datasets/coco/images/val2017/{image_id:012d}.jpg'\n",
    "        )\n",
    "\n",
    "        # Alternative: Inference from PIL Image\n",
    "        # pil_img = Image.open(f'../../datasets/coco/images/val2017/{image_id:012d}.jpg')\n",
    "        # predictions = inference_client.predict(pil_img)\n",
    "\n",
    "        predictions = predictions.cpu().numpy()\n",
    "        boxes = xyxy2ltwh(predictions[:, :4])\n",
    "        cat_ids = [coco80_to_coco91_class()[int(x)] for x in predictions[:, -1]]\n",
    "        scores = predictions[:, -2]\n",
    "\n",
    "        for box, cat, score in zip(boxes, cat_ids, scores):\n",
    "            my_predictions.append({\n",
    "                'image_id': image_id,\n",
    "                'file_name': f'{image_id:012d}.jpg',\n",
    "                'category_id': cat,\n",
    "                'bbox': box.tolist(),\n",
    "                'score': score.item()\n",
    "            })"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6e1f1d5-9236-4158-b6e9-4c72bcd150c9",
   "metadata": {},
   "source": [
    "## Creating prediction file and computing metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "56a4f064-abcc-47b1-8d7e-e1ced880db4d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading annotations into memory...\n",
      "Done (t=0.48s)\n",
      "creating index...\n",
      "index created!\n",
      "Loading and preparing results...\n",
      "DONE (t=2.52s)\n",
      "creating index...\n",
      "index created!\n",
      "Running per image evaluation...\n",
      "Evaluate annotation type *bbox*\n",
      "DONE (t=21.24s).\n",
      "Accumulating evaluation results...\n",
      "DONE (t=4.38s).\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.536\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.704\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.585\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.370\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.587\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.691\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.388\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.641\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.685\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.522\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.737\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.819\n"
     ]
    }
   ],
   "source": [
    "with open('my_predictions.json', 'w') as f:\n",
    "    json.dump(my_predictions, f)\n",
    "    \n",
    "annFile = '../../datasets/coco/annotations/instances_val2017.json'\n",
    "coco_gt = COCO(annFile)\n",
    "coco_dt = coco_gt.loadRes('my_predictions.json')\n",
    "\n",
    "coco_eval = COCOeval(coco_gt, coco_dt, iouType='bbox')\n",
    "coco_eval.evaluate()\n",
    "coco_eval.accumulate()\n",
    "coco_eval.summarize()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93b582ee-eab5-4c33-87d9-ed333cc8e8ef",
   "metadata": {},
   "source": [
    "# Result AP @[IoU=0.50:0.95]: 0.546 (torch) vs 0.536 (TensorRT+Triton)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Paligemma Detection",
   "language": "python",
   "name": "paligemma-detection"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
